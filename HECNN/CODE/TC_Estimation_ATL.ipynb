{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.read_csv(\"3B42_600KM/3B42_list_check.csv\")\n",
    "v = v[[\"GIS_ID\", \"VMAX\"]]\n",
    "v.VMAX -= v.VMAX.min()\n",
    "v.VMAX.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_table(\"3B42_600KM/CSV/ATL_199801_TD_1998072712_400.csv\", header = None, sep = ',', engine = \"python\")\n",
    "\n",
    "b = a[9:33]\n",
    "print(b.shape)\n",
    "b = b.iloc[:, 9:33]\n",
    "print(b.shape)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"training_data_previous_vmax.csv\")\n",
    "train = train[[\"file\", \"VMAX\", \"VMAX_N06H\", \"VMAX_N12H\"]]\n",
    "len(train.file)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test_data_previous_vmax.csv\")\n",
    "#test = test[[\"file\", \"VMAX\", \"VMAX_N06H\", \"VMAX_N12H\"]]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"3B42_600KM/CSV/\" + train.file[0], header = None)\n",
    "a.head()\n",
    "pvmax = np.array([train.VMAX_N06H[0], train.VMAX_N12H[0]])\n",
    "pvmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = []\n",
    "train_vmax = []\n",
    "train_label = []\n",
    "test_img = []\n",
    "test_vmax = []\n",
    "test_label = []\n",
    "for f in range(len(train.file)) :\n",
    "    filename = \"3B42_600KM/CSV/\" + train.file[f]\n",
    "    try:\n",
    "        temp = pd.read_csv(filename, header = None)\n",
    "        if (temp.shape != (44,44)):\n",
    "            continue\n",
    "        temp = temp[9:33]\n",
    "        temp = temp.iloc[:, 9:33]\n",
    "        temp = np.array(temp)\n",
    "        train_img.append(temp)\n",
    "        lab = train.VMAX[f]\n",
    "        train_label.append(lab)\n",
    "#         pvmax = np.array([train.VMAX_N06H[f], train.VMAX_N12H[f]])\n",
    "#         train_vmax.append(pvmax)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "for f in range(len(test.file)) :\n",
    "    filename = \"3B42_600KM/CSV/\" + test.file[f]\n",
    "    try:\n",
    "        temp = pd.read_csv(filename, header = None)\n",
    "        if (temp.shape != (44,44)):\n",
    "            continue\n",
    "        temp = temp[9:33]\n",
    "        temp = temp.iloc[:, 9:33]\n",
    "        temp = np.array(temp)\n",
    "        test_img.append(temp)\n",
    "        lab = test.VMAX[f]\n",
    "        test_label.append(lab)\n",
    "#         pvmax = np.array([test.VMAX_N06H[f], test.VMAX_N12H[f]])\n",
    "#         test_vmax.append(pvmax)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_img))\n",
    "print(len(train_vmax))\n",
    "print(len(train_label))\n",
    "print(len(test_img))\n",
    "print(len(test_vmax))\n",
    "print(len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img = train_img\n",
    "X_train_vmax = train_vmax\n",
    "y_train = train_label\n",
    "X_test_img = test_img\n",
    "X_test_vmax = test_vmax\n",
    "y_test = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img = np.array(X_train_img)\n",
    "X_train_img = X_train_img.reshape(-1,24,24,1)\n",
    "X_train_img = X_train_img.astype('float32')\n",
    "X_train_vmax = np.array(X_train_vmax)\n",
    "X_train_vmax = X_train_vmax.reshape(-1,2)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_img = np.array(X_test_img)\n",
    "X_test_img = X_test_img.reshape(-1,24,24,1)\n",
    "X_test_img = X_test_img.astype('float32')\n",
    "X_test_vmax = np.array(X_test_vmax)\n",
    "X_test_vmax = X_test_vmax.reshape(-1,2)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model1 = keras.Sequential([\n",
    "   keras.layers.Conv2D(64,5, activation = 'relu', input_shape = (24,24,1)),\n",
    "   keras.layers.Conv2D(64,5, activation = 'relu'),\n",
    "   keras.layers.Conv2D(64,1, activation = 'relu'),\n",
    "   keras.layers.MaxPool2D((2,2), strides = 2),\n",
    "   keras.layers.BatchNormalization(),\n",
    "   keras.layers.Conv2D(64, 4, activation='relu'),\n",
    "   keras.layers.Conv2D(64, 4, activation='relu'),\n",
    "   keras.layers.Conv2D(256,1, activation = 'relu'),\n",
    "   keras.layers.BatchNormalization(),\n",
    "   keras.layers.Flatten(),\n",
    "   keras.layers.Dense(256),\n",
    "   keras.layers.Dense(165)\n",
    "])\n",
    "\n",
    "model2 = keras.Sequential([\n",
    "   keras.layers.Conv2D(256, 5, activation='relu', input_shape=(24,24,1)),\n",
    "   keras.layers.MaxPool2D(2,2),\n",
    "   keras.layers.BatchNormalization(),\n",
    "   keras.layers.Conv2D(128, 1, activation = 'relu'),\n",
    "   keras.layers.Conv2D(128,3, activation = 'relu'), \n",
    "   keras.layers.MaxPool2D(2,2),\n",
    "   keras.layers.BatchNormalization(),\n",
    "   keras.layers.Conv2D(64, 1, activation = 'relu'),\n",
    "   keras.layers.Conv2D(64,2, activation = 'relu'), \n",
    "   keras.layers.MaxPool2D(2,2),\n",
    "   keras.layers.BatchNormalization(),\n",
    "   keras.layers.Flatten(),\n",
    "   keras.layers.Dense(165, activation = 'linear')\n",
    "])\n",
    "model3 = keras.Sequential([\n",
    "    keras.layers.Conv2D(256, (5,2), activation='relu', input_shape=(24,24,1)),\n",
    "    keras.layers.Conv2D(256, (2,5), activation = 'relu'),\n",
    "    keras.layers.MaxPool2D(2,2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(128,3, activation = 'relu'), \n",
    "    keras.layers.MaxPool2D(2,2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64,2, activation = 'relu'), \n",
    "    keras.layers.MaxPool2D(2,2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(165)\n",
    "])\n",
    "model4 = keras.Sequential([\n",
    "    keras.layers.Conv2D(256, (5,5), activation = 'relu', input_shape = (24,24,1)), \n",
    "    keras.layers.MaxPool2D(2,2), \n",
    "    keras.layers.Flatten(), \n",
    "    keras.layers.Dense(165)\n",
    "])\n",
    "\n",
    "\n",
    "model1.summary()\n",
    "model2.summary()\n",
    "model3.summary()\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmax_input = keras.Input(shape =(2,), name = \"vmax_layer\")\n",
    "img_input = keras.Input(shape =(24, 24, 1), name = \"img_layer\")\n",
    "\n",
    "w = keras.layers.Conv2D(64,5) (img_input)\n",
    "w = keras.layers.Conv2D(64,5)(w)\n",
    "w = keras.layers.Conv2D(64,1)(w)\n",
    "w = keras.layers.BatchNormalization()(w)\n",
    "w = keras.activations.relu(w)\n",
    "w = keras.layers.MaxPool2D(2,2)(w)\n",
    "w = keras.layers.Conv2D(64, 4)(w)\n",
    "w = keras.layers.Conv2D(64, 4)(w)\n",
    "w = keras.layers.Conv2D(256,1)(w)\n",
    "w = keras.layers.BatchNormalization()(w)\n",
    "img_output1 = keras.layers.Flatten()(w)\n",
    "\n",
    "merged_model1 = keras.layers.concatenate([img_output1, vmax_input])\n",
    "output_layer1 = keras.layers.Dense(256)(merged_model1)\n",
    "output_layer1 = keras.layers.Dense(165)(output_layer1)\n",
    "\n",
    "new_model1 = keras.Model(inputs = [img_input, vmax_input], outputs = output_layer1, name = \"model_1\")\n",
    "\n",
    "new_model1.summary()\n",
    "\n",
    "x = keras.layers.Conv2D(256, 5) (img_input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.activations.relu(x)\n",
    "x = keras.layers.MaxPool2D(2,2)(x)\n",
    "x = keras.layers.Conv2D(128,1, activation = 'relu')(x)\n",
    "x = keras.layers.Conv2D(128,3)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.activations.relu(x)\n",
    "x = keras.layers.MaxPool2D(2,2)(x)\n",
    "x = keras.layers.Conv2D(64,1, activation = 'relu')(x)\n",
    "x = keras.layers.Conv2D(64,2)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.activations.relu(x)\n",
    "x = keras.layers.MaxPool2D(2,2)(x)\n",
    "img_output2 = keras.layers.Flatten()(x)\n",
    "\n",
    "merged_model2 = keras.layers.concatenate([img_output2, vmax_input])\n",
    "output_layer2 = keras.layers.Dense(165)(merged_model2)\n",
    "\n",
    "new_model2 = keras.Model(inputs = [img_input, vmax_input], outputs = output_layer2, name = \"model_2\")\n",
    "\n",
    "new_model2.summary()\n",
    "\n",
    "y = keras.layers.Conv2D(256, (5,2))(img_input)\n",
    "y = keras.layers.Conv2D(256, (2,5))(y)\n",
    "y = keras.layers.BatchNormalization()(y)\n",
    "y = keras.activations.relu(y)\n",
    "y = keras.layers.MaxPool2D(2,2)(y)\n",
    "y = keras.layers.Conv2D(128,3)(y)\n",
    "y = keras.layers.BatchNormalization()(y)\n",
    "y = keras.activations.relu(y)\n",
    "y = keras.layers.MaxPool2D(2,2)(y)\n",
    "y = keras.layers.Conv2D(64,2)(y)\n",
    "y = keras.layers.BatchNormalization()(y)\n",
    "y = keras.activations.relu(y)\n",
    "y = keras.layers.MaxPool2D(2,2)(y)\n",
    "img_output3 = keras.layers.Flatten()(y)\n",
    "\n",
    "merged_model3 = keras.layers.concatenate([img_output3, vmax_input])\n",
    "output_layer3 = keras.layers.Dense(165)(merged_model3)\n",
    "\n",
    "new_model3 = keras.Model(inputs = [img_input, vmax_input], outputs = output_layer3, name = \"model_3\")\n",
    "\n",
    "new_model3.summary()\n",
    "\n",
    "z = keras.layers.Conv2D(256, (5,5))(img_input)\n",
    "z = keras.layers.MaxPool2D(2,2)(z)\n",
    "img_output4 = keras.layers.Flatten()(z)\n",
    "\n",
    "merged_model4 = keras.layers.concatenate([img_output4, vmax_input])\n",
    "output_layer4 = keras.layers.Dense(165)(merged_model4)\n",
    "\n",
    "new_model4 = keras.Model(inputs = [img_input, vmax_input], outputs = output_layer4, name = \"model_4\")\n",
    "\n",
    "new_model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              metrics=['mae', 'mse'])\n",
    "model2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              metrics=['mae', 'mse'])\n",
    "model3.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              metrics=['mae', 'mse'])\n",
    "model4.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.fit(X_train_img, y_train, epochs=3, batch_size=32, validation_split = 0.1)\n",
    "res = model3.evaluate(X_test_img, y_test)\n",
    "print(\"MAE = \" + str(res[0]))\n",
    "print(\"RMSE = \" + str((res[2]) ** 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model4.fit([X_train_img, X_train_vmax], y_train, epochs=1, batch_size=16, validation_split = 0.1)\n",
    "res = new_model4.evaluate([X_test_img, X_test_vmax], y_test)\n",
    "print(\"MAE = \" + str(res[0]))\n",
    "print(\"RMSE = \" + str((res[2]) ** 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model4.fit([X_train_img, X_train_vmax], y_train, epochs=1, batch_size=16, validation_split = 0.1)\n",
    "res = new_model4.evaluate([X_test_img, X_test_vmax], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE = \" + str(res[0]))\n",
    "print(\"RMSE = \" + str((res[2]) ** 0.5))\n",
    "preds = model1.predict(X_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.average(preds, axis = 1)\n",
    "x.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['model4_preds'] = x\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(abs(test.VMAX-test.model4_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"~/Documents/Python/predicted_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
